{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.9.0+cu102].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "\n",
    "device = torch.device ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print ('device:[%s].'%(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train:\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "mnist_test:\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akzns\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data/',train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root='./data/', train=False,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "print('mnist_train:\\n',mnist_train,'\\n')\n",
    "print('mnist_test:\\n',mnist_test,'\\n')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "class ConvolutionalNeuralNetworkClass(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Neural Network (CNN) Class\n",
    "    \"\"\"\n",
    "    def __init__(self,name='cnn',xdim=[1,28,28],\n",
    "                 ksize=3,cdims=[32,64],hdims=[1024,128],ydim=10,\n",
    "                 USE_BATCHNORM=False):\n",
    "        super(ConvolutionalNeuralNetworkClass,self).__init__()\n",
    "        self.name = name\n",
    "        self.xdim = xdim\n",
    "        self.ksize = ksize\n",
    "        self.cdims = cdims\n",
    "        self.hdims = hdims\n",
    "        self.ydim = ydim\n",
    "        self.USE_BATCHNORM = USE_BATCHNORM\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.layers = []\n",
    "        prev_cdim = self.xdim[0]\n",
    "        for cdim in self.cdims: # for each hidden layer\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(in_channels = prev_cdim,\n",
    "                    out_channels = cdim,\n",
    "                    kernel_size=self.ksize,\n",
    "                    stride=(1,1),\n",
    "                    padding=self.ksize//2)) # convlution \n",
    "            if self.USE_BATCHNORM:\n",
    "                self.layers.append(nn.BatchNorm2d(cdim)) # batch-norm\n",
    "            self.layers.append(nn.ReLU(True))  # activation\n",
    "            self.layers.append(nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))) # max-pooling \n",
    "            self.layers.append(nn.Dropout2d(p=0.5))  # dropout\n",
    "            prev_cdim = cdim\n",
    "\n",
    "        # Dense layers\n",
    "        self.layers.append(nn.Flatten())\n",
    "        prev_hdim = prev_cdim*(self.xdim[1]//(2**len(self.cdims)))*(self.xdim[2]//(2**len(self.cdims)))\n",
    "        for hdim in self.hdims:\n",
    "            self.layers.append(nn.Linear(\n",
    "                # FILL IN HERE\n",
    "                prev_hdim,hdim,bias=True\n",
    "                               ))\n",
    "            self.layers.append(nn.ReLU(True))  # activation\n",
    "            prev_hdim = hdim\n",
    "        # Final layer (without activation)\n",
    "        self.layers.append(nn.Linear(prev_hdim,self.ydim,bias=True))\n",
    "\n",
    "        # Concatenate all layers \n",
    "        self.net = nn.Sequential()\n",
    "        for l_idx,layer in enumerate(self.layers):\n",
    "            layer_name = \"%s_%02d\"%(type(layer).__name__.lower(),l_idx)\n",
    "            self.net.add_module(layer_name,layer)\n",
    "        self.init_param() # initialize parameters\n",
    "        \n",
    "    def init_param(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d): # init conv\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m,nn.BatchNorm2d): # init BN\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear): # lnit dense\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "C = ConvolutionalNeuralNetworkClass(\n",
    "    name='cnn',xdim=[1,28,28],ksize=3,cdims=[32,64],\n",
    "    hdims=[32],ydim=10).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optm = optim.Adam(C.parameters(),lr=1e-3)\n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] name:[net.conv2d_00.weight] shape:[(32, 1, 3, 3)].\n",
      "    val:[ 0.686 -0.755  0.474  0.157 -0.531]\n",
      "[1] name:[net.conv2d_00.bias] shape:[(32,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[2] name:[net.conv2d_04.weight] shape:[(64, 32, 3, 3)].\n",
      "    val:[ 0.07  -0.002 -0.071  0.053 -0.041]\n",
      "[3] name:[net.conv2d_04.bias] shape:[(64,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[4] name:[net.linear_09.weight] shape:[(32, 3136)].\n",
      "    val:[ 0.004 -0.014 -0.004  0.035 -0.037]\n",
      "[5] name:[net.linear_09.bias] shape:[(32,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[6] name:[net.linear_11.weight] shape:[(10, 32)].\n",
      "    val:[-0.481 -0.507  0.176  0.488 -0.118]\n",
      "[7] name:[net.linear_11.bias] shape:[(10,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "Total number of parameters:[119,530].\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_param = 0\n",
    "for p_idx,(param_name,param) in enumerate(C.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        param_numpy = param.detach().cpu().numpy() # to numpy array \n",
    "        n_param += len(param_numpy.reshape(-1))\n",
    "        print (\"[%d] name:[%s] shape:[%s].\"%(p_idx,param_name,param_numpy.shape))\n",
    "        print (\"    val:%s\"%(param_numpy.reshape(-1)[:5]))\n",
    "print (\"Total number of parameters:[%s].\"%(format(n_param,',d')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Forward Path of the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akzns\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_torch:\n",
      " tensor([[[[0.981, 0.719, 0.606,  ..., 0.561, 0.603, 0.772],\n",
      "          [0.835, 0.103, 0.329,  ..., 0.813, 0.913, 0.392],\n",
      "          [0.250, 0.006, 0.795,  ..., 0.527, 0.455, 0.992],\n",
      "          ...,\n",
      "          [0.869, 0.735, 0.886,  ..., 0.124, 0.718, 0.416],\n",
      "          [0.305, 0.862, 0.737,  ..., 0.545, 0.374, 0.170],\n",
      "          [0.406, 0.806, 0.079,  ..., 0.564, 0.719, 0.109]]],\n",
      "\n",
      "\n",
      "        [[[0.827, 0.137, 0.529,  ..., 0.652, 0.266, 0.786],\n",
      "          [0.221, 0.643, 0.939,  ..., 0.282, 0.506, 0.117],\n",
      "          [0.672, 0.585, 0.596,  ..., 0.943, 0.081, 0.580],\n",
      "          ...,\n",
      "          [0.816, 0.041, 0.202,  ..., 0.391, 0.031, 0.575],\n",
      "          [0.316, 0.690, 0.126,  ..., 0.243, 0.623, 0.373],\n",
      "          [0.140, 0.609, 0.034,  ..., 0.272, 0.849, 0.079]]]], device='cuda:0')\n",
      "y_torch:\n",
      " tensor([[ 7.118, -2.334, -2.910, -0.727, -2.049, -1.110,  7.007, -2.895,  0.321,\n",
      "          2.478],\n",
      "        [-0.583,  0.270, -0.245,  0.940, -2.292, -3.005,  0.554, -2.064, -0.141,\n",
      "          0.659]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "\n",
      "x_numpy (2, 1, 28, 28):\n",
      " [[[[0.981 0.719 0.606 ... 0.561 0.603 0.772]\n",
      "   [0.835 0.103 0.329 ... 0.813 0.913 0.392]\n",
      "   [0.25  0.006 0.795 ... 0.527 0.455 0.992]\n",
      "   ...\n",
      "   [0.869 0.735 0.886 ... 0.124 0.718 0.416]\n",
      "   [0.305 0.862 0.737 ... 0.545 0.374 0.17 ]\n",
      "   [0.406 0.806 0.079 ... 0.564 0.719 0.109]]]\n",
      "\n",
      "\n",
      " [[[0.827 0.137 0.529 ... 0.652 0.266 0.786]\n",
      "   [0.221 0.643 0.939 ... 0.282 0.506 0.117]\n",
      "   [0.672 0.585 0.596 ... 0.943 0.081 0.58 ]\n",
      "   ...\n",
      "   [0.816 0.041 0.202 ... 0.391 0.031 0.575]\n",
      "   [0.316 0.69  0.126 ... 0.243 0.623 0.373]\n",
      "   [0.14  0.609 0.034 ... 0.272 0.849 0.079]]]]\n",
      "y_numpy (2, 10):\n",
      " [[ 7.118 -2.334 -2.91  -0.727 -2.049 -1.11   7.007 -2.895  0.321  2.478]\n",
      " [-0.583  0.27  -0.245  0.94  -2.292 -3.005  0.554 -2.064 -0.141  0.659]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "torch.set_printoptions(precision=3)\n",
    "x_numpy = np.random.rand(2,1,28,28)\n",
    "x_torch = torch.from_numpy(x_numpy).float().to(device)\n",
    "y_torch = C.forward(x_torch) # forward path\n",
    "y_numpy = y_torch.detach().cpu().numpy() # torch tensor to numpy array\n",
    "print (\"x_torch:\\n\",x_torch)\n",
    "print (\"y_torch:\\n\",y_torch)\n",
    "print (\"\\nx_numpy %s:\\n\"%(x_numpy.shape,),x_numpy)\n",
    "print (\"y_numpy %s:\\n\"%(y_numpy.shape,),y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def func_eval(model,data_iter,device):\n",
    "    with torch.no_grad():\n",
    "        n_total,n_correct = 0,0\n",
    "        model.eval() # evaluate (affects DropOut and BN)\n",
    "        \n",
    "        for batch_in,batch_out in data_iter:\n",
    "            y_trgt = batch_out.to(device)\n",
    "            \n",
    "            model_pred = model(batch_in.view(-1,1,28,28).to(device))\n",
    "            \n",
    "            _,y_pred = torch.max(model_pred.data,1)\n",
    "            \n",
    "            n_correct += (y_pred==y_trgt).sum().item()\n",
    "            \n",
    "            n_total += batch_in.size(0)\n",
    "            \n",
    "        val_accr = (n_correct/n_total)\n",
    "        \n",
    "        model.train() # back to train mode \n",
    "        \n",
    "    return val_accr\n",
    "\n",
    "\n",
    "print (\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accr:[0.179] test_accr:[0.174].\n"
     ]
    }
   ],
   "source": [
    "C.init_param() # initialize parameters\n",
    "train_accr = func_eval(C,train_iter,device)\n",
    "test_accr = func_eval(C,test_iter,device)\n",
    "print (\"train_accr:[%.3f] test_accr:[%.3f].\"%(train_accr,test_accr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training.\n",
      "epoch:[0] loss:[0.569] train_accr:[0.953] test_accr:[0.956].\n",
      "epoch:[1] loss:[0.184] train_accr:[0.973] test_accr:[0.975].\n",
      "epoch:[2] loss:[0.132] train_accr:[0.979] test_accr:[0.980].\n",
      "epoch:[3] loss:[0.106] train_accr:[0.983] test_accr:[0.982].\n",
      "epoch:[4] loss:[0.096] train_accr:[0.984] test_accr:[0.983].\n",
      "epoch:[5] loss:[0.082] train_accr:[0.987] test_accr:[0.987].\n",
      "epoch:[6] loss:[0.078] train_accr:[0.987] test_accr:[0.986].\n",
      "epoch:[7] loss:[0.073] train_accr:[0.989] test_accr:[0.988].\n",
      "epoch:[8] loss:[0.065] train_accr:[0.989] test_accr:[0.987].\n",
      "epoch:[9] loss:[0.063] train_accr:[0.992] test_accr:[0.989].\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Start training.\")\n",
    "C.init_param() # initialize parameters\n",
    "C.train() # to train mode \n",
    "EPOCHS,print_every = 10,1\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_val_sum = 0\n",
    "    for batch_in,batch_out in train_iter:\n",
    "        # Forward path\n",
    "        y_pred = C.forward(batch_in.view(-1,1,28,28).to(device))\n",
    "        loss_out = loss(y_pred,batch_out.to(device))\n",
    "        # Update\n",
    "        # FILL IN HERE      # reset gradient \n",
    "        optm.zero_grad()\n",
    "        # FILL IN HERE      # backpropagate\n",
    "        loss_out.backward()\n",
    "        # FILL IN HERE      # optimizer update\n",
    "        optm.step()\n",
    "        loss_val_sum += loss_out\n",
    "    loss_val_avg = loss_val_sum/len(train_iter)\n",
    "    # Print\n",
    "    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
    "        train_accr = func_eval(C,train_iter,device)\n",
    "        test_accr = func_eval(C,test_iter,device)\n",
    "        print (\"epoch:[%d] loss:[%.3f] train_accr:[%.3f] test_accr:[%.3f].\"%\n",
    "               (epoch,loss_val_avg,train_accr,test_accr))\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 25\n",
    "sample_indices = np.random.choice(len(mnist_test.targets),n_sample,replace=False)\n",
    "test_x = mnist_test.data[sample_indices]\n",
    "test_y = mnist_test.targets[sample_indices]\n",
    "with torch.no_grad():\n",
    "    C.eval() # to evaluation mode \n",
    "    y_pred = C.forward(test_x.view(-1,1,28,28).type(torch.float).to(device)/255.)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "plt.figure(figsize=(10,10))\n",
    "for idx in range(n_sample):\n",
    "    plt.subplot(5, 5, idx+1)\n",
    "    plt.imshow(test_x[idx], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Pred:%d, Label:%d\"%(y_pred[idx],test_y[idx]))\n",
    "plt.show()    \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
